{
 "cells": [
  {
   "cell_type": "code",
   "id": "afe18cce-f661-44e3-966a-f6253025b02a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T14:33:27.734012Z",
     "start_time": "2025-06-23T14:33:27.729498Z"
    }
   },
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "id": "cd7ee575-a612-410c-8d4b-0d201e220eb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T14:33:27.748139Z",
     "start_time": "2025-06-23T14:33:27.738110Z"
    }
   },
   "source": [
    "def accept_cookies(driver):\n",
    "    \"\"\"Akzeptiert das Cookie-Banner wenn vorhanden.\"\"\"\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        cookie_button = wait.until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.ID, \"onetrust-accept-btn-handler\")\n",
    "            )\n",
    "        )\n",
    "        cookie_button.click()\n",
    "        print(\"Cookie-Banner akzeptiert\")\n",
    "        time.sleep(1)  # Kurze Pause nach Klick\n",
    "    except TimeoutException:\n",
    "        print(\"Kein Cookie-Banner gefunden oder bereits akzeptiert\")\n",
    "\n",
    "def fix_umlauts(text):\n",
    "    \"\"\"Korrigiert falsch kodierte Umlaute.\"\"\"\n",
    "    replacements = {\n",
    "        'Ã¤': 'ä', 'Ã„': 'Ä', 'Ã¶': 'ö', 'Ã–': 'Ö',\n",
    "        'Ã¼': 'ü', 'Ãœ': 'Ü', 'ÃŸ': 'ß'\n",
    "    }\n",
    "    for wrong, correct in replacements.items():\n",
    "        text = text.replace(wrong, correct)\n",
    "    return text\n",
    "\n",
    "def slugify(text: str) -> str:\n",
    "    \"\"\"Wandelt Text in URL-Slug um.\"\"\"\n",
    "    text = fix_umlauts(text.lower())\n",
    "    replacements = {\n",
    "        'ä': 'ae', 'ö': 'oe', 'ü': 'ue', 'ß': 'ss',\n",
    "        ' ': '-', '/': '-'\n",
    "    }\n",
    "    for orig, repl in replacements.items():\n",
    "        text = text.replace(orig, repl)\n",
    "    return text\n",
    "\n",
    "def parse_salary(pill_text):\n",
    "    \"\"\"Extrahiert Gehaltsangaben.\"\"\"\n",
    "    clean_text = pill_text.replace('\\xa0', ' ').strip()\n",
    "    pattern = r\"\"\"(?:ab\\s*)?(\\d{1,3}(?:\\.?\\d{3})*(?:,\\d{1,2})?)\\s*€\\s*(?:[-–—]\\s*(\\d{1,3}(?:\\.?\\d{3})*(?:,\\d{1,2})?)\\s*€\\s*)?(monatlich|jährlich)?\"\"\"\n",
    "    match = re.search(pattern, clean_text, re.IGNORECASE | re.VERBOSE)\n",
    "    if not match:\n",
    "        return \"keine Angabe\"\n",
    "\n",
    "    try:\n",
    "        def parse_euro_number(num_str):\n",
    "            return float(num_str.replace('.', '').replace(',', '.'))\n",
    "\n",
    "        lower = parse_euro_number(match.group(1))\n",
    "        upper = parse_euro_number(match.group(2)) if match.group(2) else lower\n",
    "        avg_salary = (lower + upper) / 2\n",
    "        zeitraum = match.group(3).lower() if match.group(3) else \"jährlich\"\n",
    "\n",
    "        if zeitraum == \"monatlich\":\n",
    "            avg_salary *= 14\n",
    "\n",
    "        return str(round(avg_salary)) if avg_salary >= 15000 else \"keine Angabe\"\n",
    "    except:\n",
    "        return \"keine Angabe\"\n",
    "\n",
    "def extract_city(job_element, target_city):\n",
    "    \"\"\"Extrahiert die Stadt aus dem Job-Element.\"\"\"\n",
    "    location_container = job_element.find('span', class_='m-jobsListItem__locations')\n",
    "    if location_container:\n",
    "        links = location_container.find_all('a', class_='m-jobsListItem__location')\n",
    "        for link in links:\n",
    "            text = link.get_text(strip=True).lower()\n",
    "            if target_city in text:\n",
    "                return target_city.capitalize()\n",
    "    return None\n",
    "\n",
    "def click_load_more(driver):\n",
    "    \"\"\"Klickt den 'Weitere Jobs anzeigen'-Button.\"\"\"\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        button = wait.until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.CSS_SELECTOR, \"button.m-loadMoreJobsButton__button\")\n",
    "            )\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", button)\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"arguments[0].click();\", button)\n",
    "        time.sleep(3)\n",
    "        return True\n",
    "    except (TimeoutException):\n",
    "        return False\n"
   ],
   "outputs": [],
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "id": "cd43de61-f5af-4ce6-bc3b-758c365d484e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T14:33:27.812412Z",
     "start_time": "2025-06-23T14:33:27.805410Z"
    }
   },
   "source": [
    "def scrape_jobs_karriere(driver, query=\"data-analyst\", locations=[\"wien\"], max_attempts=10):\n",
    "    \"\"\"Hauptfunktion zum Scrapen von Jobs.\"\"\"\n",
    "    jobs = []\n",
    "    query_slug = slugify(query)\n",
    "\n",
    "    for city_slug in locations:\n",
    "        print(f\"\\nStarte Suche für {city_slug.capitalize()}...\")\n",
    "        url = f\"https://www.karriere.at/jobs/{query_slug}/{city_slug}\"\n",
    "        driver.get(url)\n",
    "\n",
    "        # Warte auf Seitenladevorgang und akzeptiere Cookies\n",
    "        time.sleep(5)\n",
    "        accept_cookies(driver)\n",
    "\n",
    "        # Lade alle verfügbaren Jobs\n",
    "        attempt = 0\n",
    "        while attempt < max_attempts:\n",
    "            if not click_load_more(driver):\n",
    "                break\n",
    "            attempt += 1\n",
    "            print(f\"Lade weitere Jobs... Versuch {attempt}/{max_attempts}\")\n",
    "\n",
    "        # Parse die Jobdaten\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        job_items = soup.find_all(\"div\", class_=\"m-jobsListItem\")\n",
    "        print(f\"Gefundene Jobs für {city_slug.capitalize()}: {len(job_items)}\")\n",
    "\n",
    "        for job in job_items:\n",
    "            title_tag = job.find(\"a\", class_=\"m-jobsListItem__titleLink\")\n",
    "            job_title = fix_umlauts(title_tag.get_text(strip=True)) if title_tag else \"Kein Jobtitel\"\n",
    "\n",
    "            city = extract_city(job, city_slug)\n",
    "            if not city:\n",
    "                continue\n",
    "\n",
    "            salary_annual = \"keine Angabe\"\n",
    "            salary_pills = job.find_all(\"span\", class_=lambda x: x and \"m-jobsListItem__pill\" in x)\n",
    "            for pill in salary_pills:\n",
    "                pill_text = pill.get_text(strip=True)\n",
    "                if \"€\" in pill_text:\n",
    "                    salary_annual = parse_salary(pill_text)\n",
    "                    break\n",
    "\n",
    "            jobs.append({\n",
    "                \"job_title\": job_title,\n",
    "                \"city\": city,\n",
    "                \"country\": \"Austria\",\n",
    "                \"annual_salary\": salary_annual\n",
    "            })\n",
    "\n",
    "    return jobs\n"
   ],
   "outputs": [],
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "id": "9e492d0c-ea53-4c69-bda0-3019e78e73dd",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T14:36:04.104312Z",
     "start_time": "2025-06-23T14:33:27.869060Z"
    }
   },
   "source": [
    "# Hauptprogramm\n",
    "if __name__ == \"__main__\":\n",
    "    options = Options()\n",
    "    options.headless = False  # Für Debugging sichtbar machen\n",
    "    service = Service(GeckoDriverManager().install())\n",
    "    driver = webdriver.Firefox(service=service, options=options)\n",
    "\n",
    "    try:\n",
    "        cities = [\"wien\", \"linz\", \"graz\", \"salzburg\", \"innsbruck\"]\n",
    "\n",
    "        jobs = scrape_jobs_karriere(\n",
    "            driver,\n",
    "            query=\"Data Engineer\",\n",
    "            locations=cities,\n",
    "            max_attempts=10\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame(jobs)\n",
    "        print(f\"\\nGesamtanzahl gescrapte Jobs: {len(df)}\")\n",
    "        print(df.head())\n",
    "\n",
    "        df.to_csv(\"../output/data_analyst_engineer_scientist_austria.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        print(\"Ergebnisse gespeichert in 'data_analyst_engineer_scientist_austria.csv'\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starte Suche für Wien...\n",
      "Kein Cookie-Banner gefunden oder bereits akzeptiert\n",
      "Lade weitere Jobs... Versuch 1/10\n",
      "Lade weitere Jobs... Versuch 2/10\n",
      "Lade weitere Jobs... Versuch 3/10\n",
      "Gefundene Jobs für Wien: 59\n",
      "\n",
      "Starte Suche für Linz...\n",
      "Kein Cookie-Banner gefunden oder bereits akzeptiert\n",
      "Gefundene Jobs für Linz: 15\n",
      "\n",
      "Starte Suche für Graz...\n",
      "Kein Cookie-Banner gefunden oder bereits akzeptiert\n",
      "Lade weitere Jobs... Versuch 1/10\n",
      "Gefundene Jobs für Graz: 26\n",
      "\n",
      "Starte Suche für Salzburg...\n",
      "Kein Cookie-Banner gefunden oder bereits akzeptiert\n",
      "Gefundene Jobs für Salzburg: 15\n",
      "\n",
      "Starte Suche für Innsbruck...\n",
      "Kein Cookie-Banner gefunden oder bereits akzeptiert\n",
      "Gefundene Jobs für Innsbruck: 15\n",
      "\n",
      "Gesamtanzahl gescrapte Jobs: 100\n",
      "                                         job_title  city  country  \\\n",
      "0                          Splunk Engineer (m/w/d)  Wien  Austria   \n",
      "1  Systems Engineer IT-Security Operations (m/w/d)  Wien  Austria   \n",
      "2      Systems Engineer Network Operations (m/w/d)  Wien  Austria   \n",
      "3       Werkstudentin (w/m/d) Data Engineer Junior  Wien  Austria   \n",
      "4                Data Engineer (m/w/d) - befristet  Wien  Austria   \n",
      "\n",
      "  annual_salary  \n",
      "0         55000  \n",
      "1         56000  \n",
      "2         56000  \n",
      "3         42314  \n",
      "4         64534  \n",
      "Ergebnisse gespeichert in 'data_engineer_austria_karriere.csv'\n"
     ]
    }
   ],
   "execution_count": 113
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
